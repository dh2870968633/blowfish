
[{"content":" HBase # HBase是什么？ # 简介 # ​\t是一个开源的、高可靠性、高性能、面向列（这里指列族，非列式存储）、可伸缩、实时读写的分布式数据库，其设计思想来源于 Google 的 BigTable 论文。利用 Hadoop HDFS 作为其文件存储系统，利用 ZooKeeper 作为其分布式协同服务。主要用来存储非结构化和半结构化的松散数据（列式存储 NoSQL 数据库）。总而言之：HBase是一种基于HDFS的分布式、面向列的非关系型数据库。\n特点 # 易扩展：\nHBase 的扩展性主要体现在两个方面，一个是基于运算能力（HRegionServer） 的扩展，通过增加 HRegionSever 节点 的数量，提升 HBase 上层的处理能力；另一个是基于存储能力的扩展（HDFS），通过增加 DataNode 节点数量对存储层的 进行扩容，提升 HBase 的数据存储能力。\n容量大：\nHBase 单表可以有十亿行、百万列，数据矩阵横向和纵向两个维度所支持的数据量级都非常具有弹性。HBase 的主要 作用就是面向 PB 级别数据的实时入库和快速随机访问。这主要源于上述易扩展的特点，使得 HBase 通过扩展来存储海量 的数据。\n面向列：\nHBase 是根据列族来存储数据的，列族下面可以有非常多的列。列式存储的最大好处就是，其数据在表中是按照某列 存储的，这样在查询只需要少数几个字段时，能大大减少读取的数据量。还可以动态增加列，可单独对列进行各方面的操 作。\n多版本：\nHBase 的每个列的数据存储支持多个 Version，比如住址列，可能有多个变更。\n稀疏性：\n为空的列并不占用存储空间，表可以设计的非常稀疏。不必像关系型数据库那样需要预先知道所有列名然后再进行 null 填充。\n高可靠：\nWAL（Write Ahead Log）日志先行机制，保证数据写入的时候不会因为集群异常而导致写入数据丢失。Replication 机 制，保证了集群在出现严重问题的时候，数据不会发生丢失或者损坏。HBase 底层使用 HDFS，本身也有备份。\n高性能：\n底层的LSM（Log-Structured Merge-tree）数据结构和Rowkey有序排列等设计，使得HBase具备非常高的写入性能，同时对于高并发的场景也具备很好的适应能力。\n应用场景？ # HBase 是一种 NoSQL（非关系型） 数据库，这意味着它不像传统的 RDBMS（关系型） 数据库那样支持 SQL 作为查询语言。HBase 是一种分布式存储的数据库，技术上来讲，它更像是分布式存储而不是分布式数据库，它缺少很多 RDBMS 系统的特性，比如列类型，辅助索引，触发器和高级查询语言等。\nHBase适合数据量要特别大，如果有十亿或百亿行数据，那么 HBase 是一个很好的选择，如果只有几百万行甚至不到的数据量，RDBMS 是一个很好的选择。因为数据量小的话，真正能工作的机器量少，剩余的机器都处于空闲的状态。其次，如果你不需要辅助索引，静态类型的列，事务等特性可以考虑 HBase。但是一个已经用 RDBMS的系统想要切换到 HBase，则需要重新设计系统。最后，保证硬件资源足够，每个 HDFS 集群在少于 5 个节点的时候，都不能表现的很好。因为 HDFS 默认的复制数量是 3，再加上一个 NameNode。其实HBase 在单机环境下也能运行，但是请在开发环境中进行使用。\n适合 HBase 的应用：\n存储业务数据：车辆 GPS 信息，司机点位信息，用户操作信息，设备访问信息。 存储日志数据：架构监控数据（登录日志，中间件访问日志，推送日志，短信邮件发送记录），业务操作日志信息。 存储业务附件：UDFS 系统（去中心化文件系统）存储图像，视频，文档等附件信息。 HBase 和 RDBMS 的区别：\n属性 HBase RDBMS 数据类型 只有字符串 丰富的数据类型 数据操作 增删改查，不支持 JOIN 各种各样的函数与表连接 存储模式 列族式存储 表结构和行式存储 数据保护 更新后仍然保留旧版本 替换 可伸缩性 轻易增加节点 需要中间层，牺牲性能 数据模型 # 在 HBase 表中，一条数据拥有一个全局唯一的主键（RowKey）和任意数量的列（Column Qualifier），每个列的数据 存储支持多个版本（Version），一列或多列组成一个列族（Column Family），同一个列族中列的数据在物理上都存储在 同一个 HFile 中。这样基于列存储的数据结构有利于数据缓存和查询。 所以，在 HBase 中定位一条数据需要通过：RowKey → Column Family → Column Qualifier → Version。\nHBase 表中的数据是疏松地存储的，因此用户可以动态地为数据定义各种不同的列。HBase 中的数据按主键排序（字 典序），同时 HBase 会将表按主键划分为多个 HRegion 存储在不同的 HRegionServer 上，以完成数据的分布式存储和读 取。\nNameSpace # 命名空间类似于关系型数据库中的数据库的概念，相当于表在逻辑上的分组（不同表放不同库中），命名空间是可以管理维护的，可以创建，删除或更改命名空间。HBase 有两个特殊预定义的命名空间：\ndefault：没有明确指定命名空间的表将默认在此命名空间下 hbase：系统命名空间，用于包含 HBase 的内部表（namespace）和元数据表(meta)（存了整个HBase中的所有其他的表的【数据与region，以及region与RegionServer的映射】）\u0026ndash;通过该机制能快速定位到数据。提高读写效率。 Table # 这里的Table和关系型数据库中的表差不多，行列的结构组成。\nRowKey\u0026ndash;行健 # RowKey类似于RDBMS中的主键，是一行数据的唯一标识。RowKey 可以是任意字符串（最大长度是64KB，实际应用中长度一般为 10-100 Bytes），RowKey 以字节数组保存。存储数据时，数据会按照 RowKey 的字典序排序存储，所以设计 RowKey 时，要充分利用排序存储这个特性，将经常一起读取的行存放到一起。\n字典排序：它基于字符的编码值（如ASCII码值或Unicode码值）进行排序。字符串被视为由若干个字符组成的序列，排序结果取决于字符之间的比较顺序。\n排序原理：\n字符串的比较是从左到右逐个字符进行的。 首先比较第一个字符，如果相同，则继续比较第二个字符，以此类推，直到遇到不同的字符或某个字符串结束。 如果某个字符串是另一个字符串的前缀，则较短的字符串排在前面。 如果两个字符串的所有字符都相同，则它们在排序中的位置由实现细节决定，但通常认为它们是等价的。 Column Family # Column Family 即列族，HBase 基于列划分数据的物理存储，同一个列族中列的数据在物理上都存储在同一个 HFile 中。一个列族可以包含任意多列，一般同一类的列会放在一个列族中。\nHBase 在创建表的时候就必须指定列族。HBase 的列族不是越多越好，官方推荐一个表的列族数量最好\u0026lt;=3，过多的列族不利于 HBase 数据的管理和索引。\nColumn Qualifier # 列族下的列，列标识，列标识是可以改变的，因此每一行可能有不同的列标识。使用的时候必须 列族:列 ，列可以根据需求动态添加或者删除。\nTimestamp # Timestamp 是实现 HBase 多版本的关键。在 HBase 中，使用不同的 Timestamp 来标识相同 RowKey 对应的不同版本 的数据。相同 RowKey 的数据按照 Timestamp 倒序排列，默认查询的是最新的版本，当然用户也可以指定 Timestamp 的值 来读取指定版本的数据。\nHBase 通过 RowKey 和 Column Family，Column Qualifier 来确定一个存贮单元（cell单元格），然后再通过时间戳来进行索引，找到对应的数据。为了避免数据存在过多版本而造成管理（包括存贮和索引）负担，HBase 提供了两种数据版本回收方案：\n一是保存数据的最后 n 个版本 二是保存最近一段时间内的版本（比如最近七天） Cell # Cell 由 Row，Column Family，Column Qualifier，Version 组成\u0026ndash;最后定位到的那个单元格。Cell 中的数据是没有类型的，全部使用字节码形式存贮，因为 HDFS 上的数据都是字节数组。HDFS中，虽然文件在物理上被切分成了多个块Block，但从逻辑上看，每个块仍然是由字节数组组成的。这意味着，无论数据在HDFS中如何被切分和存储，其本质仍然是字节序列。\n架构模型 # ​\tHBase 可以将数据存储在本地文件系统，也可以存储在 HDFS 文件系统。在生产环境中，HBase 一般运行在 HDFS 上，以 HDFS 作为基础的存储设施。用户通过 HBase Client 提供的 Shell 或 Java API 来访问 HBase 数据库，以完成数据的 写入和读取。HBase 集群主要由 HMaster、HRegionServer 和 ZooKeeper 组成。\nClient # HBase Client 为用户提供了访问 HBase 的接口，可以通过元数据表（客户端负责发送请求到数据库）来定位到目标数 据的 HRegionServer。客户端连接的方式有很多种：比如 HBase Shell 和 Java API。\n这里说的客户端请求指的是DDL、DML、DQL这些跟SQL语言差不多的操作，这里主要用的是HBase提供的相关操作的命令。\nZooKeeper # HBase 通过 ZooKeeper 来完成选举 HMaster、监控 HRegionServer、元数据管理等工作。主要工作职责如下：\n选举 HMaster：保证任何时候，集群中只有一个 HMaster处于Active状态（HMaster Active），其余处于备用状态（HMaster Backup）。 监控 HRegionServer（节点探活）：实时监控 HRegionServer 的状态，将 HRegionServer 的上下线信息实时报告给HMaster； 元数据管理维护：存储了HBase中的所有元数据信息（hbase:meta 元数据表\u0026mdash;-HRegion的寻址入口），存储 HBase 的 Schema，包括有哪些 Table，每个 Table 有哪些 行键、列族、列限定符和时间戳、单元格cell。 HMaster # HMaster 是 HBase 整个集群的主节点，负责整个集群的管理工作，HMaster 可以实现高可用（Active 和 Backup），通过 ZooKeeper 来维护主备节点的切换。\nHMaster的主要作用：\n管理分配：HMaster负责管理RegionServer的注册和心跳，监控RegionServer的状态。管理和分配 HRegion，启动的时候分配 HRegion 到具体的 HRegionServer。在RegionServer出现故障时，HMaster会重新分配Region，确保数据的可用性和服务的连续性。 负载均衡：一方面负责将用户的数据均衡地分布在各个 HRegionServer 上，防止 某个HRegionServer 数据倾斜过载。另一 方面负责将用户的请求均衡地分布在各个 HRegionServer 上，防止 HRegionServer 请求过热； **表管理：**HMaster负责创建、删除表以及进行表的修改操作（是把命令发送给RegionServer，让它去干活）。将表的定义信息同步到所有RegionServer上。 **维护数据：**发现失效的 HRegion，并将失效的 HRegion 分配到正常的 HRegionServer 上。当某个 HRegionServer 下线 时迁移其内部的 HRegion 到其他 HRegionServer 上。 处理客户端请求：客户端请求先通过zookeeper获取到meta元数据表的信息。再通过HMaster节点，HMaster会根据请求的表和RowKey确定请求的Region所在的RegionServer，并将请求转发给对应的RegionServer进行处理。 权限控制：当用户尝试执行涉及表结构或集群管理的操作时，HMaster 会验证用户的权限。HMaster 可以接收来自管理员的权限变更请求，并更新相应的权限信息。当用户尝试执行创建表、删除表、修改表结构等操作时，HMaster 会检查用户的权限。 HRegionServer # HRegionServer 直接对接用户的读写请求，是真正干活的节点，属于 HBase 具体数据的管理者。\n主要作用：\n实时和 HMaster 保持心跳，汇报当前节点的信息； 当接收到 HMaster 的命令创建表时，会分配一个 HRegion 对应一张表； 负责切分在运行过程中变得过大的 HRegion； 当 HRegionServer 意外关闭的时候，当前节点的 HRegion 会被其他 HRegionServer 管理； 维护 HMaster 分配给它的 HRegion，处理对这些 HRegion 的 IO 请求； 当客户端发送 DML 和 DQL 操作时，HRegionServer 负责和客户端建立连接； WAL：Write Ahead Log 日志先行。记录了数据写入、更新日志，它被用来做故障恢复；会先把数据写入到HLog中。 MemStore：【写缓存】，数据首先会被写入到 MemStore 中（在写入日志之后）。每个 HRegion 的每个 Column Family 都会有一个MemStore。 负责与底层的 HDFS 交互，存储数据（HLog、HFile）到 HDFS。 BlockCache：【读缓存】，在内存中存储了最常访问的数据，采用 LRU 机制进行淘汰。\u0026mdash;\u0026ndash;具体见读流程。 当某个 HRegionServer 宕机后，zookeeper会通知HMaster进行失效备援。下线的 HRegionServer 所负责的 HRegion 暂 时停止对外提供服务，HMaster 会将该 HRegionServer 所负责的 HRegion 转移到其他 HRegionServer 上，并且会对下线的 HRegionServer 进行日志重放，将 MemStore 中还未持久化到磁盘中的数据进行恢复。\n当某台 HRegionServer Failover（故障转移） 的时候，整个过程中 HRegion 中的数据是不可用的，因为它是缺失的。因此，HBase 属 于 CP 架构，降低了可用性，具备强一致性读/写。设想一下，如果 Redo （恢复）过程中的 HRegion 能够响应请求，那么可用性提 高了，则必然返回不一致的数据（因为 Redo 可能还没完成），那么 HBase 的一致性就降低了。\nHRegion # 一个 HRegionServer 上包含了多个 HRegion，一个 HRegion 由多个 Store 组成，每个 Store 都对应一个 Column Family，Store 包含 1 个 MemStore 和 0 或多个StoreFile 组成。\nHBase 将表中的数据基于 RowKey 的不同范围划分到不同 HRegion 上，每个HRegion 都负责一定范围的数据存储和访问。当HBase表被创建时，它通常会被初始化为一个HRegion，包含整个行键空间。随着数据的不断插入，HRegion的大小会逐渐增长。HRegionServer会定期检查HRegion的大小，发现其大小超过了预设的阈值（10G==所有的StoreFile文件大小）时，触发分区操作按一定的规则进行分区。为了实现负载均衡，有可能新的分区会被分到其他的 HRegionServer 上。\n为了防止前期数据的处理都集中在一个 HRegionServer，我们可以根据自己的业务进行预分区。\n这样即使有一张百亿条数据的表，由于数据被划分到不同的 HRegion上，每个 HRegion 都可以独立地进行读写，HBase 读写数据的时候还可以与多 HRegion 分布式并发操作，所以访问速度并不会有太大的降低。\n负载均衡：防止一个RegionServer的压力过大，把Region分散到不同的RegionServer上\u0026ndash;HMaster负责。 Split （分Region）：在 HBase 中 Split 是一个很重要的功能，HBase 是通过把数据分配到一定数量的 HRegion 来达到负载均衡的。一个Table 会被分配到一个或多个 HRegion 中，这些 HRegion 会被分配到一个或者多个 HRegionServer 中。在自动 Split 策略 中，当一个 HRegion 达到一定的大小就会自动 Split 成两个 HRegion。Table 在 HRegion 中是按照 RowKey 来排序的，并且 一个 RowKey 所对应的行只会存储在一个 HRegion 中，这一点保证了 HBase 的强一致性。 当一个 Table 刚被创建的时候，HBase 默认的分配一个 HRegion 给 Table。也就是说这个时候，所有的读写请求都会访 问到同一个 HRegionServer 的同一个 HRegion 中，这个时候就达不到负载均衡的效果了，集群中的其他 HRegionServer 可 能处于比较空闲的状态。解决这个问题可以用 pre-splitting 在创建 Table 时提前生成多个 HRegion。 在 Table 初始化的时候如果不配置的话，HBase 是不知道如何去 Split HRegion 的，因为 HBase 不知道应该把哪个 RowKey 作为 Split 的开始点。如果我们可以大概预测到 RowKey 的分布，我们可以使用 pre-spliting 来帮助我们提前 Split HRegion。 如果我们的预测不是特别准确，还是会导致某个 HRegion 过热被集中访问，不过还好我们还有 auto-split，默认按 10G 自动切分。但是如果文件到达 9G 后迟迟未到 10G 此时对于 HBase 来说是比较难受的。最好的办法就是首先预测 Split 的切 分点，做 pre-splitting，后面再交给 auto-split 来处理。 HBase 在每次数据合并之后都会针对相应 HRegion 生成一个 requestSplit 请求，requestSplit 首先会执行 checkSplit， 检测 FileSize 是否达到阈值，如果超过阈值，就进行切分。 HBase 自带了两种 pre-split 的算法，分别是 HexStringSplit 和 UniformSplit 。如果我们的 RowKey 是十六进制 的字符串作为前缀的，就比较适合用 HexStringSplit 作为 pre-split 的算法。例如，我们使用 HexHash(prefix) 作为 RowKey 的前缀，其中 HexHash 为得到十六进制字符串的 hash 算法。我们也可以用我们自己的 Split 算法。 当一个 HRegion 达到一定的大小，他会自动 Split 成两个 HRegion。如果我们的 HBase 版本是 0.94 之后，那么默认的 有三种自动 Split 的策略，ConstantSizeRegionSplitPolicy，IncreasingToUpperBoundRegionSplitPolicy 还有 KeyPrefixRegionSplitPolicy。 在 0.94 版本之前 ConstantSizeRegionSplitPolicy 是默认和唯一的 Split 策略。当某个 Store（对应一个 Column Family） 的大小大于配置值 hbase.hregion.max.filesize 的时候（默认 10G）HRegion 就会自动分裂。 而 0.94 版本之后 IncreasingToUpperBoundRegionSplitPolicy 是默认的 Split 策略。这个策略中，最小的分裂大小和 Table 的某个 HRegionServer 的 HRegion 个数有关，当 StoreFile 的大小大于以下公式得出的值的时候就会 Split。公式如 下： # R 为同一个 Table 中在同一个 HRegionServer 中的 HRegion 的个数 Min(R^2 * \u0026#34;hbase.hregion.memstore.flush.size\u0026#34;, \u0026#34;hbase.hregion.max.filesize\u0026#34;) 例如：\nhbase.hregion.memstore.flush.size 默认值 128MB。 hbase.hregion.max.filesize 默认值为 10GB。 如果初始时 R=1 ，那么 Min(128MB, 10GB)=128MB ，也就是说在第一个 Flush 的时候就会触发分裂操作。 当 R=2 的时候 Min(22128MB, 10GB)=512MB ，当某个 StoreFile 大小达到 512MB 的时候，就会触发分裂。 如此类推，当 R=9 的时候，StoreFile 达到 10GB 的时候就会分裂，也就是说当 R\u0026gt;=9 的时候，StoreFile 达到 10GB 的时候就会分裂。 ​\tKeyPrefixRegionSplitPolicy 可以保证相同的前缀的 RowKey 保存在同一个 HRegion 中。指定 RowKey 前缀位数划分HRegion，通过读取 KeyPrefixRegionSplitPolicy.prefix_length 属性，该属性为数字类型，表示前缀长度，在进行 Split 时，按此长度对 SplitPoint 进行截取。此种策略比较适合固定前缀的 RowKey。当 Table 中没有设置该属性，指定此策略效果等同与使用IncreasingToUpperBoundRegionSplitPolicy。 我们可以通过配置 hbase.regionserver.region.split.policy 来指定 Split 策略，也可以写我们自己的 Split 策略。\nStore # 一个 HRegion 由多个 Store 组成，每个 Store 都对应一个 Column Family，Store 包含 1 个 MemStore 和 0 或多个 StoreFile 组成。\nMemStore：作为 HBase 的内存数据存储，数据的写操作会先写到 MemStore 中，当 MemStore 中的数据增长到指定阈 值（默认 128M）后，HRegionServer 会启动 FlushCache 进程将 MemStore 中的数据写入 StoreFile 持久化存储(刷写)，每次写 入后都形成一个单独的 StoreFile。当客户端检索数据时，先在 MemStore 中查找，如果 MemStore 中不存在，则会在 StoreFile 中继续查找。 StoreFile：保存实际数据的物理文件，它是HBase数据存储系统的基本单位，用于在HDFS（Hadoop Distributed File System）上存储数据。HBase 以 StoreFile 的大小来判断是否需要切分 HRegion。当一个 HRegion 中所有 StoreFile 的大小和数量都增长到超过指定阈值时，HMaster会把当前 HRegion 分割Split为两个，切分后其中一个 HRegion 会被转移到其他的 HRegionServer 上，实现负载均衡。 HFile：HFile 和 StoreFile 是同一个文件，只不过站在 HDFS 的角度称这个文件为 HFile，站在 HBase 的角度就称这个文件为StoreFile。是 HBase 在 HDFS 中存储数据的格式，它包含多层的索引，这样在 HBase 检索数据的时候就不用完全的加载整个文件。 StoreFile是HBase中保存数据的物理文件，而HFile是这些物理文件的底层实现格式。 HLog # 一个 HRegionServer 只有一个 HLog 文件。负责记录数据的操作日志，当 HBase 出现故障时可以进行日志重放、故障恢复。例如磁盘掉电导致 MemStore 中的数据没有持久化存储到 StoreFile，这时就可以通过 HLog 日志重放来恢复数据。\n在数据由（Write-Ahead Logging，预写日志）机制写入HLog后，数据还会被写到MemStore中。HLog文件会持久化存储到HDFS中。\nHDFS # HDFS 为 HBase 提供底层数据存储服务，同时为 HBase 提供高可用支持。HBase 将 HLog 存储在 HDFS 上，当服务器发 生异常宕机时，可以日志重放 HLog 来恢复数据。\n","date":"2024-07-01","externalUrl":null,"permalink":"/docs/hbase/","section":"Docs","summary":"HBase # HBase是什么？ # 简介 # ​\t是一个开源的、高可靠性、高性能、面向列（这里指列族，非列式存储）、可伸缩、实时读写的分布式数据库，其设计思想来源于 Google 的 BigTable 论文。利用 Hadoop HDFS 作为其文件存储系统，利用 ZooKeeper 作为其分布式协同服务。主要用来存储非结构化和半结构化的松散数据（列式存储 NoSQL 数据库）。总而言之：HBase是一种基于HDFS的分布式、面向列的非关系型数据库。","title":"HBase","type":"docs"},{"content":"\rShell 编程概述 # Shell 本身并不是内核的一部分，它只是站在内核的基础上编写的一个应用程序，它和 QQ、迅雷、Firefox 等其它软件没有什么区别。然而 Shell 也有着它的特殊性，就是开机立马启动，并呈现在用户面前；用户通过 Shell 来使用 Linux，不启动 Shell 的话，用户就没办法使用 Linux。\n在计算机科学中，Shell 俗称壳（用来区别于核），是指“为使用者提供操作界面”的软件（command interpreter，命令解析器）。它类似于 DOS 下的 COMMAND.COM 和后来的 cmd.exe。它接收用户命令，然后调用相应的应用程序。\nShell 并不是简单的堆砌命令，我们还可以在 Shell 中编程，这和使用 C++、Java、Python 等常见的编程语言并没有什么两样。\nShell 虽然没有 C++、Java、Python 等强大，但也支持了基本的编程元素，例如：\n变量、数组、字符串、注释、加减乘除、逻辑运算等概念； if\u0026hellip;else 选择结构，case\u0026hellip;in 开关语句，for、while、until 循环； 函数，包括用户自定义的函数和内置函数（例如 printf、export、eval 等）。 站在这个角度讲，Shell 也是一种编程语言，它的编译器（解释器）是 Shell 这个程序。我们平时所说的 Shell，有时候是指连接用户和内核的这个程序，有时候也指 Shell 编程。\nShell 名词解释 # Shell # Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 也是一个命令行解释器，是用户和内核之间的接口。用户可以在 Shell 中输入命令，然后，它解释命令来执行所需的任务。此外，它还可以执行程序和 Shell 脚本。Shell 脚本是一组命令，用户应该遵循标准语法向 Shell 写入命令。\n总的来说，Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。Shell 既是一种命令语言，又是一种程序设计语言，如果要与内核打交道就必须学习 Shell 语言。\n分类 # Shell 是提供与内核沟通接口的命令解释器程序，但实际上 Shell 是这种解释器的统称，Linux 系统的 Shell 种类很多，包括 Bourne Shell（简称 sh）、Bourne Again Shell（简称 bash）、C Shell（简称 csh）、K shell（简称 ksh）、Shell for Root 等等。如下图：\n也就是说 sh 和 bash 都是 Linux 系统 Shell 的一种，其中 bash 命令是 sh 命令的超集，大多数 sh 脚本都可以在 bash 下运行。Linux 系统中预设默认使用的就是 bash。\n要想知道操作系统支持哪种Shell类型，可在终端中输入以下命令：\n[root@node01 ~]# cat /etc/shells /bin/sh /bin/bash /usr/bin/sh /usr/bin/bash 要想知道 bash 在操作系统中具体的位置，可通过以下命令查看：\n[root@node01 ~]# which bash sh /usr/bin/bash /usr/bin/sh She Bang # She Bang 是 Shell 脚本开头字符#!也可以叫 Sha Bang，当 Shell 文件被 Linux 系统读取时，内核会通过#!表示的值（0x23, 0x21）识别出随后的解释器路径并调用，最后再将整个脚本内容传递给解释器。由于 Shell 当中#字符同时表示注释，因此 Shell 解释脚本文件时会自动忽略该行。\n总结：#!就是告诉系统解释此脚本文件的 Shell 程序在哪（其后路径所指定的程序）。例如：\n#!/bin/bash echo \u0026#34;Hello World!\u0026#34; She Bang 的格式很重要，格式不正确会导致命令工作不正常。因此，在创建脚本时，要始终记住 She Bang 格式的这两点：\n它应该始终在脚本的第一行。 在#!和解释器的路径之间，#之前不应有任何空格。 echo是 bash 中的内置命令，用于通过传递参数来显示标准输出。它是用于将文本/字符串行打印到屏幕上的最广泛使用的命令。\n脚本 # 在计算机编程中，脚本是用于适当的运行时环境的一组命令，这些命令用于自动执行任务。\n我们经常说的 Shell 脚本，其实就是利用 Shell 的功能，编写能够直接运行的脚本文件。\n第一个 Shell 脚本 # 几乎所有的编程语言教程都是从著名的“Hello World”开始，出于对这种传统的尊重，我们的第一个 Shell 脚本也输出“Hello World”。\n打开文本编辑器，新建一个文本文件，并命名为 hello.sh。\n扩展名sh代表 shell，扩展名并不影响脚本执行，见名知意就好。\n在 hello.sh 中输入代码：\n#!/bin/bash echo \u0026#34;Hello World!\u0026#34; #!是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行，即使用哪一种 Shell；后面的/bin/bash就是指明了解释器的具体位置。\necho命令用于向标准输出文件（Standard Output，stdout，一般就是指显示器）输出文本。在.sh文件中使用命令与在终端直接输入命令的效果是一样的。\n接下来使用bash或sh运行脚本：\n[root@node01 ~]# bash hello.sh Hello World! Shell 脚本执行 # 脚本的执行并非只有bash和sh，还有source和.且它们之间还存在一些细微的差异，接下来我们详细的给大家讲解一下。\n使用路径 # 格式：相对路径/脚本.sh或绝对路径/脚本.sh。\n注意：脚本文件必须为可执行文件（拥有 x 权限）。\n范例：\n[root@node01 ~]# ls -l total 4 -rw-r--r-- 1 root root 33 May 29 11:57 hello.sh [root@node01 ~]# /root/hello.sh bash: /root/hello.sh: Permission denied [root@node01 ~]# chmod ug+x hello.sh [root@node01 ~]# ./hello.sh Hello World! [root@node01 ~]# /root/hello.sh Hello World! bash 或 sh # 格式：bash 脚本.sh或sh 脚本.sh。\n范例：\n[root@node01 ~]# ls -l total 4 -rw-r--r-- 1 root root 33 May 29 11:57 hello.sh [root@node01 ~]# bash hello.sh Hello World! [root@node01 ~]# sh hello.sh Hello World! source 或 . # 格式：source 脚本.sh或. 脚本.sh\n范例：\n[root@node01 ~]# ls -l total 4 -rw-r--r-- 1 root root 33 May 29 11:57 hello.sh [root@node01 ~]# . hello.sh Hello World! [root@node01 ~]# source hello.sh Hello World! 区别 # bash 或 sh 执行脚本时会新开一个 bash，不同 bash 中的变量无法共享。而 source 或 . 是在同一个 bash 里面执行的，所以变量可以共享。\n范例：\n[root@node01 ~]# cat hello.sh #!/bin/bash echo \u0026#34;Hello World!\u0026#34; echo ${name} [root@node01 ~]# name=mrhelloworld [root@node01 ~]# bash hello.sh Hello World! [root@node01 ~]# sh hello.sh Hello World! [root@node01 ~]# . hello.sh Hello World! mrhelloworld [root@node01 ~]# source hello.sh Hello World! mrhelloworld 在脚本中添加ping baidu.com的指令，用不同的方式重新执行脚本并查看进程。\n[root@node01 ~]# echo \u0026#34;ping baidu.com\u0026#34; \u0026gt;\u0026gt; hello.sh [root@node01 ~]# cat hello.sh #!/bin/bash echo \u0026#34;Hello World!\u0026#34; echo ${name} ping baidu.com bash：\n[root@node01 ~]# bash hello.sh [root@node01 ~]# ps -ef root 4447 4445 0 12:15 pts/0 00:00:00 -bash root 4494 4447 0 12:17 pts/0 00:00:00 bash hello.sh root 4495 4494 0 12:17 pts/0 00:00:00 ping baidu.com sh：\n[root@node01 ~]# sh hello.sh [root@node01 ~]# ps -ef root 4447 4445 0 12:15 pts/0 00:00:00 -bash root 4497 4447 0 12:18 pts/0 00:00:00 sh hello.sh root 4498 4497 0 12:18 pts/0 00:00:00 ping baidu.com source：\n[root@node01 ~]# source hello.sh [root@node01 ~]# ps -ef root 4447 4445 0 12:15 pts/0 00:00:00 -bash root 4502 4447 0 12:19 pts/0 00:00:00 ping baidu.com .：\n[root@node01 ~]# . hello.sh [root@node01 ~]# ps -ef root 4447 4445 0 12:15 pts/0 00:00:00 -bash root 4508 4447 0 12:25 pts/0 00:00:00 ping baidu.com 怎么解决这个问题呢？可以使用export命令，它可以将当前进程的变量传递给子进程去使用，如下：\n[root@node01 ~]# export name=mrhelloworld [root@node01 ~]# bash hello.sh Hello World! mrhelloworld 所以，将来在配置环境变量（profile 文件）的时候，所有的变量前必须加export。\nShell 基础 # 注释 # 单行注释 # 要在 bash 中编写单行注释，必须在注释的开头使用井号#。\n#!/bin/bash # 我是注释 多行注释 # 有两种方法可以在 bash 脚本中插入多行注释：\n通过在\u0026lt;\u0026lt; COMMENT和COMMENT之间加上注释，可以在 bash 脚本中编写多行注释。 也可以通过将注释括在: '和单引号'之间来编写多行注释。 #!/bin/bash \u0026lt;\u0026lt; EOF 我是注释 我是注释 我是注释 EOF echo \u0026#34;Hello World!\u0026#34; 提示：EOF 表示 End Of File，表示文件结尾，这里代指从哪开始到哪结束。EOF 只是一个名称而已，可以使用任意非关键字名称进行替换，例如 COMMENT，通常都使用 EOF。\n或者：\n#!/bin/bash : \u0026#39; 我是注释 我是注释 我是注释 \u0026#39; echo \u0026#34;Hello World\u0026#34; 变量 # 语法 # 变量是将数据或有用的信息作为值存储的容器。变量的值可以更改，并且可以多次使用。变量是任何类型的数据（例如整数，浮点数，字符等）的临时存储。\n定义变量时，变量名不加$符号，而引用变量时则需要使用$。同其他编程语言一样，Shell 的变量声明也需要遵循一定的规则：\n可以包含字母，数字和下划线。 只能以字母和下划线开头，不能定义以任何数字开头的变量名称。 严格区分大小写。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 变量名称与值之间的等号=的两侧不能有空格。 不能使用 bash 里的关键字（可用 help 命令查看保留关键字）。 Shell 声明变量的语法格式如下：\nvariable=value variable=\u0026#39;value\u0026#39; variable=\u0026#34;value\u0026#34; variable 是变量名，value 是赋给变量的值。如果 value 不包含任何空白符（例如空格、Tab 缩进等），那么可以不使用引号；如果 value 包含了空白符，那么就必须使用引号包围起来。使用单引号和使用双引号也是有区别的，稍后我们会详细说明。\n变量定义举例：\n# 变量的声明与赋值 name=\u0026#34;zhangsan\u0026#34; # 变量的调用 echo $name echo ${name} # 修改变量的值，已定义的变量，可以被重新赋值 name=\u0026#34;lisi\u0026#34; # 只读变量 url=\u0026#34;https://www.baidu.com\u0026#34; readonly url # 测试只读变量是否可以被修改 url=\u0026#34;https://www.google.com\u0026#34; # 删除变量 unset name # 将命令结果复制给变量 info=`ls /usr/` info=$(ls /usr/) 调用变量时，变量名外面的花括号{}是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界，比如下面这种情况：\nskill=\u0026#34;Shell\u0026#34; echo \u0026#34;I am good at ${skill}Script\u0026#34; 如果不给 skill 变量加花括号，写成echo \u0026quot;I am good at $skillScript\u0026quot;，解释器就会把$skillScript当成一个变量（其值为空），代码执行结果就不是我们期望的样子了。\n调用变量时，推荐给所有变量加上花括号{}，这是个良好的编程习惯。\nShell 也支持将命令的执行结果赋值给变量，常见的有以下两种方式：\nvariable=`command` variable=$(command) 第一种方式把命令用反引号（位于 Esc 键的下方）包围起来，反引号和单引号非常相似，容易产生混淆，所以不推荐使用这种方式；第二种方式把命令用$()包围起来，区分更加明显，所以推荐使用这种方式。\n类型 # 局部变量：局部变量在脚本或命令中定义，仅在当前 Shell 实例中有效，其他 Shell 启动的程序不能访 问局部变量。例如，不同会话创建的变量无法互相访问。 环境变量：所有的程序，包括 Shell 启动的程序，都能访问环境变量，有些程序需要环境变量来保证 其正常运行。 Shell 变量：Shell 变量是由 Shell 程序设置的特殊变量。Shell 变量中有一部分是环境变量，有一部分是 局部变量。例如： # bash 在操作系统中具体的位置 echo ${BASH} # bash 版本信息 echo ${BASH_VERSION} # 操作系统的类型 echo $OSTYPE # 当前登录用户 echo ${USERNAME} # 当前用户家目录 echo ${HOME} # 当前的工作目录 echo ${PWD} 引号 # 当希望变量存储更复杂的值时，就需要使用引号。引号用于处理带有空格字符的文本和文件名。这是因为 Bash 使用空格来确定单独的项目。在 Shell 中，变量的值可以由单引号' '包围，也可以由双引号\u0026quot; \u0026quot;包围，它们到底有什么区别呢？不妨以下面的代码为例来说明：\n#!/bin/bash name=\u0026#34;zhangsan\u0026#34; echo \u0026#39;My name is ${name}\u0026#39; echo \u0026#34;My name is ${name}\u0026#34; 运行结果如下：\nMy name is ${name} My name is zhangsan 单引号' '包围变量的值时，单引号里面是什么就输出什么，即使内容中有变量和命令（命令需要反引起来）也会把它们原样输出。这种方式比较适合定义显示纯字符串的情况，即不希望解析变量、命令等的场景。\n双引号\u0026quot; \u0026quot;包围变量的值时，输出时会先解析里面的变量和命令，而不是把双引号中的变量名和命令原样输出。这种方式比较适合字符串中附带有变量和命令并且想将其解析后再输出的变量定义。\n位置参数 # 运行 Shell 脚本文件时我们还可以给它传递一些参数，这些参数在脚本文件内部可以使用$n的形式来接收。例如，$1表示第一个参数，$2表示第二个参数，依次类推。\n这种通过$n的形式来接收的参数，在 Shell 中称为位置参数。在讲解变量的命名时，我们提到变量的名字必须以字母或者下划线开头，不能以数字开头；但是位置参数却偏偏是数字，这和变量的命名规则是相悖的，所以我们将它们视为“特殊变量”。\n注意：如果参数个数太多，达到或者超过了 10 个，那么就得用${n}的形式来接收了，例如 ${10}、${23}。{}的作用是为了帮助解释器识别参数的边界，这跟使用变量时加{}是一样的效果。\n除了$n，Shell 中还有$#、$*、$@、$?、$$几个特殊参数，我们将在下节讲解。\n范例 test.sh：\n#!/bin/bash echo \u0026#34;name: $1\u0026#34; echo \u0026#34;age: $2\u0026#34; 运行 test.sh，并附带参数：\n[root@node01 ~]# bash test.sh zhangsan 18 name: zhangsan age: 18 特殊变量 # 上节我们讲到了 $n，它是特殊变量的一种，用来接收位置参数。本节我们继续讲解剩下的几个特殊变量，它们分别是：$#、$*、$@、$?、$$。\n变量 含义 $$ 当前 Shell 进程 ID。对于 Shell 脚本，就是这些脚本所在的进程 ID。 $0 当前脚本的文件名。 $n 传递给脚本或函数的参数。n 为数字，表示第几个参数。例如，第一个参数是 $1，第二个参数是 $2。 $@ 传递给脚本或函数的所有参数。 $* 传递给脚本或函数的所有参数。当被双引号\u0026quot; \u0026quot;包含时，$@ 与 $* 稍有不同。 $# 传递给脚本或函数的参数个数。 $? 上个命令的退出状态，或函数的返回值。 $*和$@作用都是获取传递给脚本或函数的所有参数。在没有被双引号包围时，两者没有区别，接收到的每个参数都是独立的，用空格分隔。\n当被双引号包围时，$@与没有被双引号包围时没有变化，每个参数依然是独立的。但是$*被双引号包围时，会将所有参数看作一个整体。\n$?是一个特殊变量，用来获取上一个命令的退出状态，或者上一个函数的返回值。所谓退出状态，就是上一个命令执行后的返回结果。退出状态是一个数字，一般情况下，大部分命令执行成功会返回 0，失败返回 1，这和 C 语言的 main() 函数是类似的。\n范例 test.sh：\n#!/bin/bash echo \u0026#34;Process ID: $$\u0026#34; echo \u0026#34;File Name: $0\u0026#34; echo \u0026#34;First Parameter: $1\u0026#34; echo \u0026#34;Second Parameter: $2\u0026#34; echo \u0026#34;All parameters 1: $@\u0026#34; echo \u0026#34;All parameters 2: $*\u0026#34; echo \u0026#34;Total: $#\u0026#34; echo \u0026#34;--------------------\u0026#34; for var in \u0026#34;$@\u0026#34; do echo ${var} done echo \u0026#34;--------------------\u0026#34; for var in \u0026#34;$*\u0026#34; do echo ${var} done 运行 test.sh，并附带参数：\n[root@node01 ~]# bash test.sh Linux Shell Process ID: 4779 File Name: test.sh First Parameter: Linux Second Parameter: Shell All parameters 1: Linux Shell All parameters 2: Linux Shell Total: 2 -------------------- Linux Shell -------------------- Linux Shell $?是一个特殊变量，用来获取上一个命令的退出状态，或者上一个函数的返回值。所谓退出状态，就是上一个命令执行后的返回结果。退出状态是一个数字，一般情况下，大部分命令执行成功会返回 0，失败返回 1，这和C语言的 main() 函数是类似的。不过，也有一些命令返回其他值，表示不同类型的错误。\n范例1，$? 获取上一个命令的退出状态。test.sh：\n#!/bin/bash if [ \u0026#34;$1\u0026#34; == 100 ] then exit 0 # 参数正确，退出状态为 0 else exit 1 # 参数错误，退出状态 1 fi 例如，运行 test.sh 时传递参数 100：\n[root@node01 ~]# bash test.sh 100 [root@node01 ~]# echo $? 0 再如，运行 test.sh 时传递参数 50：\n[root@node01 ~]# bash test.sh 50 [root@node01 ~]# echo $? 1 范例2，$? 获取函数的返回值。test.sh：\n#!/bin/bash # 得到两个数相加的和 function add() { return `expr $1 + $2` } # 调用函数 add 20 30 echo $? # 获取函数返回值 运行结果如下：\n[root@node01 ~]# bash test.sh 50 有 C++、C#、Java 等编程经验的读者请注意：严格来说，Shell 函数中的 return 关键字用来表示函数的退出状态，而不是函数的返回值；Shell 不像其它编程语言，没有专门处理返回值的关键字。\n范例 2 在其它编程语言中没有任何问题，但是在 Shell 中是非常错误的，Shell 函数的返回值和其它编程语言大有不同，我们将在后面的 Shell 函数返回值中展开讨论。\n字符串 # 定义 # 字符串（String）就是一系列字符的组合。字符串是 Shell 编程中最常用的数据类型之一（除了数字和字符串，也没有其他类型了）。\n字符串可以由单引号' '包围，也可以由双引号\u0026quot; \u0026quot;包围，也可以不用引号。\n由单引号' '包围的字符串：\n任何字符都会原样输出，在其中使用变量是无效的。\n字符串中不能出现单引号，即使对单引号进行转义（\\'）也不行。\n由双引号\u0026quot; \u0026quot;包围的字符串：\n如果其中包含了某个变量，那么该变量会被解析（得到该变量的值），而不是原样输出。\n字符串中可以出现双引号，只要它被转义（\\\u0026quot;）就行。\n不被引号包围的字符串：\n不被引号包围的字符串中出现变量时也会被解析，这一点和双引号\u0026quot; \u0026quot;包围的字符串一样。\n字符串中不能出现空格，否则空格后边的字符串会作为其他变量或者命令解析。\n长度 # 在 Shell 中获取字符串长度很简单，具体方法如下：\n[root@node01 ~]# name=mrhelloworld [root@node01 ~]# echo ${#name} 12 拼接 # 在脚本语言中，字符串的拼接（也称字符串连接或者字符串合并）往往都非常简单，例如：\n在 PHP 中，使用 . 即可连接两个字符串； 在 JavaScript 中，使用 + 即可将两个字符串合并为一个。 然而，在 Shell 中你不需要使用任何运算符，只需要将两个字符串并排放在一起就能实现拼接，非常简单粗暴。范例 test.sh：\n#!/bin/bash name=\u0026#34;zhangsan\u0026#34; age=18 str1=$name$age # 中间不能有空格 str2=\u0026#34;$name $age\u0026#34; # 如果被双引号包围，那么中间可以有空格 str3=$name\u0026#34;: \u0026#34;$age # 中间可以出现别的字符串 str4=\u0026#34;$name: $age\u0026#34; # 这样写也可以 str5=\u0026#34;${name}同学: ${age}岁\u0026#34; # 这个时候需要给变量名加上大括号 echo $str1 echo $str2 echo $str3 echo $str4 echo $str5 运行 test.sh：\n[root@node01 ~]# bash test.sh zhangsan18 zhangsan 18 zhangsan: 18 zhangsan: 18 zhangsan同学: 18岁 截取 # Shell 截取字符串通常有两种方式：\n从指定位置开始截取 从指定字符（子字符串）开始截取 从指定位置开始截取 # 这种方式需要两个参数：除了指定起始位置，还需要截取长度，才能最终确定要截取的字符串。\n既然需要指定起始位置，那么就涉及到计数方向的问题，到底是从字符串左边开始计数，还是从字符串右边开始计数。答案是 Shell 同时支持两种计数方式。\n如果想从字符串的左边开始计数，那么截取字符串的具体格式如下：\n${string:start:length} 其中，string 是要截取的字符串，start 是起始位置（从左边开始，从 0 开始计数），length 是要截取的长度（省略的话表示直到字符串的末尾）。\n范例：\n[root@node01 ~]# name=mrhelloworld [root@node01 ~]# echo ${name:2} helloworld [root@node01 ~]# echo ${name:2:5} hello 如果想从字符串的右边开始计数，那么截取字符串的具体格式如下：\n${string:0-start:length} 相比从左边开始计数仅仅多了0-，这是固定的写法，专门用来表示从字符串右边开始计数。\n范例：\n[root@node01 ~]# name=mrhelloworld [root@node01 ~]# echo ${name:0-5} world [root@node01 ~]# echo ${name:0-10} helloworld [root@node01 ~]# echo ${name:0-10:5} hello 从指定字符（子字符串）开始截取 # 这种截取方式无法指定字符串长度，只能从指定字符（子字符串）截取到字符串末尾。Shell 可以截取指定字符（子字符串）右边的所有字符，也可以截取左边的所有字符。\n使用#号可以截取指定字符（或者子字符串）右边的所有字符，具体格式如下：\n${string#*chars} 其中，string 表示要截取的字符串，chars 是指定的字符（或者子字符串），*是通配符的一种，表示任意长度的字符串。*chars连起来使用的意思是：忽略左边的所有字符，直到遇见 chars（chars 不会被截取）。\n范例：\n[root@node01 ~]# url=https://www.yjxxt.com [root@node01 ~]# echo ${url#*https://} www.yjxxt.com [root@node01 ~]# echo ${url#*://} www.yjxxt.com 注意，以上写法遇到第一个匹配的字符（子字符串）就结束了，如果希望直到最后一个指定字符（子字符串）再匹配结束，那么可以使用##。例如：\n[root@node01 ~]# echo ${url#*.} yjxxt.com [root@node01 ~]# echo ${url##*.} com 使用%号可以截取指定字符（或者子字符串）左边的所有字符，具体格式如下：\n${string%chars*} 请注意*的位置，因为要截取 chars 左边的字符，而忽略 chars 右边的字符，所以*应该位于 chars 的右侧。其他方面%和#的用法相同，这里不再赘述，仅举例说明：\n[root@node01 ~]# url=https://www.yjxxt.com [root@node01 ~]# echo ${url%www*} https:// [root@node01 ~]# echo ${url%.*} https://www.yjxxt [root@node01 ~]# echo ${url%%.*} https://www 总结 # 格式 说明 ${string:start:length} 从 string 字符串的左边第 start 个字符开始，向右截取 length 个字符。 ${string:start} 从 string 字符串的左边第 start 个字符开始截取，向右直到最后。 ${string:0-start:length} 从 string 字符串的右边第 start 个字符开始，向左截取 length 个字符。 ${string:0-start} 从 string 字符串的右边第 start 个字符开始截取，向左直到最后。 ${string#*chars} 从 string 字符串第一次出现 *chars 的位置开始，截取 *chars 右边的所有字符。 ${string##*chars} 从 string 字符串最后一次出现 *chars 的位置开始，截取 *chars 右边的所有字符。 ${string%*chars} 从 string 字符串第一次出现 *chars 的位置开始，截取 *chars 左边的所有字符。 ${string%%*chars} 从 string 字符串最后一次出现 *chars 的位置开始，截取 *chars 左边的所有字符。 数组 # 和其他编程语言一样，Shell 也支持数组。数组（Array）是若干数据的集合，其中的每一份数据都称为元素（Element）。\nShell 没有限制数组的大小，理论上可以存放无限量的数据。和 C++、Java 等类似，Shell 数组元素的下标也是从 0 开始计数。\n获取数组中的元素要使用下标[index]，下标可以是一个整数，也可以是一个结果为整数的表达式；当然，下标必须大于等于 0。遗憾的是，常用的 Bash Shell 只支持一维数组，不支持多维数组。\n定义 # 在 Shell 中，用括号()来表示数组，数组元素之间用空格来分隔。由此，定义数组的一般形式为：\narray_name=(ele1 ele2 ele3 ... elen) Shell 是弱类型的，它并不要求所有数组元素的类型必须相同，例如：\narr=(20 56 \u0026#34;mrhelloworld\u0026#34;) Shell 数组的长度不是固定的，定义之后还可以增加元素。例如，对于上面的 arr 数组，它的长度是 3，使用下面的代码会在最后增加一个元素，使其长度扩展到 4：\nnums[3]=88 此外，Shell 还支持只给特定元素赋值：\nages=([3]=24 [5]=19 [10]=12) 以上代码就只给第 3、5、10 个元素赋值，所以数组长度是 3。\n获取 # 获取数组元素的值，一般使用下面的格式：\n${array_name[index]} 其中，array_name 是数组名，index 是下标。例如：\n[root@node01 ~]# echo ${arr[2]} mrhelloworld 使用@或*可以获取数组中的所有元素，例如：\n[root@node01 ~]# echo ${arr[*]} 20 56 mrhelloworld [root@node01 ~]# echo ${ages[@]} 24 19 12 长度 # 所谓数组长度，就是数组元素的个数。使用@或*可以获取数组中的所有元素，然后使用#来获取数组元素的个数，所以获取数组长度的语法如下：\n[root@node01 ~]# echo ${#arr[@]} 3 [root@node01 ~]# echo ${#ages[*]} 3 如果某个元素是字符串，还可以通过指定下标的方式获得该元素的长度，如下所示：\n[root@node01 ~]# echo ${#arr[2]} 12 拼接 # 所谓 Shell 数组拼接（数组合并），就是将两个数组连接成一个数组。\n拼接数组的思路是：先利用@或*，将数组展开成列表，然后再合并到一起。具体格式如下：\narray_new=(${array1[@]} ${array2[@]}) array_new=(${array1[*]} ${array2[*]}) 两种方式是等价的，选择其一即可。其中，array1 和 array2 是需要拼接的数组，array_new 是拼接后形成的新数组。\n范例 test.sh：\n#!/bin/bash array1=(23 56) array2=(99 \u0026#34;mrhelloworld\u0026#34;) array_new=(${array1[@]} ${array2[*]}) echo ${array_new[@]} # 也可以写作 ${array_new[*]} 运行结果如下：\n[root@node01 ~]# bash test.sh 23 56 99 mrhelloworld 删除 # 在 Shell 中，使用 unset 关键字来删除数组元素，具体格式如下：\nunset array_name[index] 其中，array_name 表示数组名，index 表示数组下标。\n如果不写下标只写数组名，则表示删除整个数组，所有元素都会消失。\n范例 test.sh：\n#!/bin/bash arr=(23 56 99 \u0026#34;mrhelloworld\u0026#34;) unset arr[1] echo ${arr[@]} unset arr echo ${arr[*]} echo \u0026#39;--------------------\u0026#39; 运行结果如下：\n[root@node01 ~]# bash test.sh 23 99 mrhelloworld -------------------- Shell 高级 # Shell 运算符 # Shell 和其他编程语言一样，支持多种运算符，包括：\n算数运算符 关系运算符 逻辑运算符 字符串运算符 文件测试运算符 算数运算符 # 但是，Shell 和其它编程语言不同，Shell 不能直接进行算数运算，必须使用数学计算命令，这让初学者感觉很困惑，也让有经验的程序员感觉很奇葩。expr 是一款表达式计算工具，使用它能完成表达式的求值操作。\n#!/bin/bash a=10 b=20 val=$(expr $a + $b) echo \u0026#34;a + b : $val\u0026#34; val=`expr $a - $b` echo \u0026#34;a - b : $val\u0026#34; val=`expr $a \\* $b` echo \u0026#34;a * b : $val\u0026#34; val=`expr $b / $a` echo \u0026#34;b / a : $val\u0026#34; val=`expr $b % $a` echo \u0026#34;b % a : $val\u0026#34; if [ $a == $b ] then echo \u0026#34;a 等于 b\u0026#34; fi if [ $a != $b ] then echo \u0026#34;a 不等于 b\u0026#34; fi 关系运算符 # 关系运算符只支持数字，不支持字符串，除非字符串的值是数字。\n#!/bin/bash a=10 b=20 if [ $a -eq $b ] then echo \u0026#34;$a -eq $b : a 等于 b\u0026#34; else echo \u0026#34;$a -eq $b: a 不等于 b\u0026#34; fi if [ $a -ne $b ] then echo \u0026#34;$a -ne $b: a 不等于 b\u0026#34; else echo \u0026#34;$a -ne $b : a 等于 b\u0026#34; fi if [ $a -gt $b ] then echo \u0026#34;$a -gt $b: a 大于 b\u0026#34; else echo \u0026#34;$a -gt $b: a 不大于 b\u0026#34; fi if [ $a -lt $b ] then echo \u0026#34;$a -lt $b: a 小于 b\u0026#34; else echo \u0026#34;$a -lt $b: a 不小于 b\u0026#34; fi if [ $a -ge $b ] then echo \u0026#34;$a -ge $b: a 大于或等于 b\u0026#34; else echo \u0026#34;$a -ge $b: a 小于 b\u0026#34; fi if [ $a -le $b ] then echo \u0026#34;$a -le $b: a 小于或等于 b\u0026#34; else echo \u0026#34;$a -le $b: a 大于 b\u0026#34; fi 逻辑运算符 # #!/bin/bash a=10 b=20 if [ $a != $b ] then echo \u0026#34;$a != $b : a 不等于 b\u0026#34; else echo \u0026#34;$a == $b: a 等于 b\u0026#34; fi if [ $a -lt 100 -a $b -gt 15 ] then echo \u0026#34;$a 小于 100 且 $b 大于 15 : 返回 true\u0026#34; else echo \u0026#34;$a 小于 100 且 $b 大于 15 : 返回 false\u0026#34; fi if [ $a -lt 100 -o $b -gt 100 ] then echo \u0026#34;$a 小于 100 或 $b 大于 100 : 返回 true\u0026#34; else echo \u0026#34;$a 小于 100 或 $b 大于 100 : 返回 false\u0026#34; fi if [ $a -lt 5 -o $b -gt 100 ] then echo \u0026#34;$a 小于 5 或 $b 大于 100 : 返回 true\u0026#34; else echo \u0026#34;$a 小于 5 或 $b 大于 100 : 返回 false\u0026#34; fi #!/bin/bash a=10 b=20 if [[ $a -lt 100 \u0026amp;\u0026amp; $b -gt 100 ]] then echo \u0026#34;返回 true\u0026#34; else echo \u0026#34;返回 false\u0026#34; fi if [[ $a -lt 100 || $b -gt 100 ]] then echo \u0026#34;返回 true\u0026#34; else echo \u0026#34;返回 false\u0026#34; fi 字符串运算符 # #!/bin/bash a=\u0026#34;abc\u0026#34; b=\u0026#34;efg\u0026#34; if [ $a = $b ] then echo \u0026#34;$a = $b : a 等于 b\u0026#34; else echo \u0026#34;$a = $b: a 不等于 b\u0026#34; fi if [ $a != $b ] then echo \u0026#34;$a != $b : a 不等于 b\u0026#34; else echo \u0026#34;$a != $b: a 等于 b\u0026#34; fi if [ -z $a ] then echo \u0026#34;-z $a : 字符串长度为 0\u0026#34; else echo \u0026#34;-z $a : 字符串长度不为 0\u0026#34; fi if [ -n \u0026#34;$a\u0026#34; ] then echo \u0026#34;-n $a : 字符串长度不为 0\u0026#34; else echo \u0026#34;-n $a : 字符串长度为 0\u0026#34; fi if [ $a ] then echo \u0026#34;$a : 字符串不为空\u0026#34; else echo \u0026#34;$a : 字符串为空\u0026#34; fi 文件测试运算符 # 操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 #!/bin/bash file=\u0026#34;/root/test.sh\u0026#34; if [ -r $file ] then echo \u0026#34;文件可读\u0026#34; else echo \u0026#34;文件不可读\u0026#34; fi if [ -w $file ] then echo \u0026#34;文件可写\u0026#34; else echo \u0026#34;文件不可写\u0026#34; fi if [ -x $file ] then echo \u0026#34;文件可执行\u0026#34; else echo \u0026#34;文件不可执行\u0026#34; fi if [ -f $file ] then echo \u0026#34;文件为普通文件\u0026#34; else echo \u0026#34;文件为特殊文件\u0026#34; fi if [ -d $file ] then echo \u0026#34;文件是个目录\u0026#34; else echo \u0026#34;文件不是个目录\u0026#34; fi if [ -s $file ] then echo \u0026#34;文件不为空\u0026#34; else echo \u0026#34;文件为空\u0026#34; fi if [ -e $file ] then echo \u0026#34;文件存在\u0026#34; else echo \u0026#34;文件不存在\u0026#34; fi echo 打印数据 # ## 显示普通字符串 echo \u0026#34;Hello World\u0026#34; ## 显示转义字符 echo \u0026#34;\\\u0026#34;Hello World\\\u0026#34;\u0026#34; ## 显示变量 name=\u0026#34;zhangsan\u0026#34; echo \u0026#34;$name Hello World\u0026#34; ## 显示换行 echo -e \u0026#34;OK! \\n\u0026#34; echo \u0026#34;Hello World\u0026#34; ## 显示不换行 echo -e \u0026#34;OK! \\c\u0026#34; echo \u0026#34;Hello World\u0026#34; ## 显示结果定向至文件 echo \u0026#34;Hello World\u0026#34; \u0026gt; myfile ## 原样输出字符串 echo \u0026#39;$name\\\u0026#34;\u0026#39; ## 显示命令执行结果，推荐方式 echo $(date) ## 显示命令执行结果 echo `date` test 命令 # Shell 中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试。\n数字\n字符串\n文件测试\n# 比较 num1=100 num2=100 if test $[num1] -eq $[num2] then echo \u0026#39;两个数相等！\u0026#39; else echo \u0026#39;两个数不相等！\u0026#39; fi Shell 流程控制 # if # if condition1 then command1 elif condition2 then command2 else commandN fi a=10 b=20 if [ $a == $b ] then echo \u0026#34;a 等于 b\u0026#34; elif [ $a -gt $b ] then echo \u0026#34;a 大于 b\u0026#34; elif [ $a -lt $b ] then echo \u0026#34;a 小于 b\u0026#34; else echo \u0026#34;没有符合的条件\u0026#34; fi case # case 语句为多选择语句。可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。 case 值 in 模式1) command1 command2 ... commandN ;; 模式2) command1 command2 ... commandN ;; esac echo \u0026#39;输入 1 到 4 之间的数字:\u0026#39; echo \u0026#39;你输入的数字为:\u0026#39; read num case $num in 1) echo \u0026#39;你选择了 1\u0026#39; ;; 2) echo \u0026#39;你选择了 2\u0026#39; ;; 3) echo \u0026#39;你选择了 3\u0026#39; ;; 4) echo \u0026#39;你选择了 4\u0026#39; ;; *) echo \u0026#39;你没有输入 1 到 4 之间的数字\u0026#39; ;; esac for # 当变量值在列表里，for循环即执行一次所有命令，使用变量名获取列表中的当前取值。\n命令可为任何有效的shell命令和语句。in列表可以包含替换、字符串和文件名。\nin列表是可选的，如果不用它，for循环使用命令行的位置参数。\nfor var in item1 item2 ... itemN do command1 command2 ... commandN done for loop in 1 2 3 4 5 do echo \u0026#34;The value is: $loop\u0026#34; done for str in \u0026#39;This is a string\u0026#39;,\u0026#39;hello moto\u0026#39; do echo $str done while循环 # while 循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。 while condition do command done # Bash let 命令，它用于执行一个或多个表达式，变量计算中不需要加上 $ 来表示变量 #!/bin/bash i=1 while(( $i\u0026lt;=5 )) do echo $i let \u0026#34;i++\u0026#34; done # 无限循环 while true do command done break # break 命令允许跳出所有循环（终止执行后面的所有循环）。 #!/bin/bash while : do echo -n \u0026#34;输入 1 到 5 之间的数字:\u0026#34; read aNum case $aNum in 1|2|3|4|5) echo \u0026#34;你输入的数字为 $aNum!\u0026#34; ;; *) echo \u0026#34;你输入的数字不是 1 到 5 之间的! 游戏结束\u0026#34; break ;; esac done continue # continue 命令不会跳出所有循环，仅仅跳出当前循环。 #!/bin/bash while : do echo -n \u0026#34;输入 1 到 5 之间的数字: \u0026#34; read aNum case $aNum in 1|2|3|4|5) echo \u0026#34;你输入的数字为 $aNum!\u0026#34; ;; *) echo \u0026#34;你输入的数字不是 1 到 5 之间的!\u0026#34; continue echo \u0026#34;游戏结束\u0026#34; ;; esac done Shell 函数 # linux shell 可以用户定义函数，然后在shell脚本中可以随便调用。 可以带function fun() 定义，也可以直接fun() 定义,不带任何参数。 参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。 #!/bin/bash ## 第一个函数------------------------------ demoFun(){ echo \u0026#34;这是我的第一个 shell 函数!\u0026#34; } echo \u0026#34;-----函数开始执行-----\u0026#34; demoFun echo \u0026#34;-----函数执行完毕-----\u0026#34; ## 函数返回值------------------------------ funWithReturn(){ echo \u0026#34;这个函数会对输入的两个数字进行相加运算...\u0026#34; echo \u0026#34;输入第一个数字: \u0026#34; read aNum echo \u0026#34;输入第二个数字: \u0026#34; read anotherNum echo \u0026#34;两个数字分别为 $aNum 和 $anotherNum !\u0026#34; return $(($aNum+$anotherNum)) } funWithReturn # 函数返回值在调用该函数后通过 $? 来获得。 echo \u0026#34;输入的两个数字之和为 $? !\u0026#34; ## 函数参数------------------------------ funWithParam(){ echo \u0026#34;第一个参数为 $1 !\u0026#34; echo \u0026#34;第二个参数为 $2 !\u0026#34; echo \u0026#34;第十个参数为 $10 !\u0026#34; # 如果参数个数太多，达到或者超过了 10 个，那么就得用 ${n} 的形式来接收了 echo \u0026#34;第十个参数为 ${10} !\u0026#34; echo \u0026#34;第十一个参数为 ${11} !\u0026#34; echo \u0026#34;参数总数有 $# 个!\u0026#34; echo \u0026#34;作为一个字符串输出所有参数 $* !\u0026#34; } funWithParam 1 2 3 4 5 6 7 8 9 Shell 实战 # 添加开机启动项 # 需求：服务器开机后自动与 cn.ntp.org.cn 同步时间。\ntouch /usr/local/scripts/auto_ntpdate.sh echo \u0026#39;#!/bin/bash\u0026#39; \u0026gt;\u0026gt; /usr/local/scripts/auto_ntpdate.sh echo \u0026#39;yum info ntp \u0026amp;\u0026amp; yum -y install ntp \u0026amp;\u0026amp; ntpdate cn.ntp.org.cn\u0026#39; \u0026gt;\u0026gt; /usr/local/scripts/auto_ntpdate.sh chmod +x /usr/local/scripts/auto_ntpdate.sh echo \u0026#39;/usr/local/scripts/auto_ntpdate.sh\u0026#39; \u0026gt;\u0026gt; /etc/rc.d/rc.local chmod +x /etc/rc.d/rc.local 虚拟机初始化脚本 # 目标服务器环境如下：\n主机名 IP node01 192.168.88.101 node02 192.168.88.102 node03 192.168.88.103 首先，使用最初始的example虚拟机克隆出一台完整虚拟机。然后，启动虚拟机并修改网络配置与主机名：\n修改网络配置中的IPADDR并重启网络； echo node01 \u0026gt; /etc/hostname修改主机名。 接下来，sh init.sh运行脚本。\n最后，拍摄快照方便后期回退。\n然后通过已经初始化完成的 node01 完整克隆出 node02 和 node03，修改它两的网络配置与主机名即可。\n虚拟机初始化脚本init.sh完整内容如下：\n#!/bin/bash ## -bash: ./init.sh: /bin/bash^M: bad interpreter: No such file or directory ## vim 或者 vi 的命令模式下，输入命令 set fileformat=unix 即可解决上述问题 echo -e \u0026#34;\\e[1;44m【在 /opt 目录和 /var 目录下创建 yjx 目录，在 /usr/local 目录下创建 scripts 目录】\\e[0m\u0026#34; sleep 2 mkdir -p /opt/yjx /var/yjx /usr/local/scripts echo -e \u0026#34;\\e[1;44m【关闭并禁用 firewalld 防火墙】\\e[0m\u0026#34; sleep 2 systemctl stop firewalld systemctl disable firewalld systemctl status firewalld echo -e \u0026#34;\\e[1;44m【关闭 SELinux】\\e[0m\u0026#34; sleep 2 sed -i \u0026#39;/^SELINUX=/c SELINUX=disabled\u0026#39; /etc/selinux/config echo -e \u0026#34;\\e[1;44m【安装 wget】\\e[0m\u0026#34; sleep 2 yum -y install wget echo -e \u0026#34;\\e[1;44m【修改 yum 源为阿里源】\\e[0m\u0026#34; sleep 2 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo yum clean all yum makecache echo -e \u0026#34;\\e[1;44m【安装常用依赖】\\e[0m\u0026#34; sleep 2 yum -y install man man-pages telnet perl net-tools openssl-devel ntp lrzsz zip unzip tree vim rsync echo -e \u0026#34;\\e[1;44m【修改时区为 Asia/Shanghai】\\e[0m\u0026#34; sleep 2 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime echo -e \u0026#34;\\e[1;44m【与中国 NTP 时间服务器 cn.ntp.org.cn 进行时间同步】\\e[0m\u0026#34; sleep 2 yum info ntp \u0026amp;\u0026amp; yum -y install ntp \u0026amp;\u0026amp; ntpdate cn.ntp.org.cn echo -e \u0026#34;\\e[1;44m【修改 hosts 文件，添加集群环境机器 IP 与域名映射】\\e[0m\u0026#34; sleep 2 echo \u0026#34;192.168.88.100 basenode\u0026#34; \u0026gt;\u0026gt; /etc/hosts echo \u0026#34;192.168.88.101 node01\u0026#34; \u0026gt;\u0026gt; /etc/hosts echo \u0026#34;192.168.88.102 node02\u0026#34; \u0026gt;\u0026gt; /etc/hosts echo \u0026#34;192.168.88.103 node03\u0026#34; \u0026gt;\u0026gt; /etc/hosts echo -e \u0026#34;\\e[1;44m【安装 JDK 并设置环境变量】\\e[0m\u0026#34; sleep 2 rpm -ivh jdk-8u351-linux-x64.rpm echo \u0026#39;export JAVA_HOME=/usr/java/jdk1.8.0_351-amd64\u0026#39; \u0026gt;\u0026gt; /etc/profile echo \u0026#39;export PATH=$JAVA_HOME/bin:$PATH\u0026#39; \u0026gt;\u0026gt; /etc/profile source /etc/profile echo -e \u0026#34;\\e[1;44m【安装 Tomcat】\\e[0m\u0026#34; sleep 2 tar -zxf apache-tomcat-9.0.72.tar.gz -C /opt/yjx/ echo -e \u0026#34;\\e[1;44m【安装 MySQL】\\e[0m\u0026#34; sleep 2 rpm -e --nodeps `rpm -qa | grep mariadb` tar -xvf mysql-8.0.18-1.el7.x86_64.rpm-bundle.tar rpm -ivh mysql-community-common-8.0.18-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-8.0.18-1.el7.x86_64.rpm rpm -ivh mysql-community-client-8.0.18-1.el7.x86_64.rpm rpm -ivh mysql-community-server-8.0.18-1.el7.x86_64.rpm rpm -ivh mysql-community-devel-8.0.18-1.el7.x86_64.rpm rpm -ivh mysql-community-libs-compat-8.0.18-1.el7.x86_64.rpm systemctl start mysqld systemctl enable mysqld temppasswd=`grep \u0026#34;A temporary password\u0026#34; /var/log/mysqld.log | awk \u0026#39;{print $NF}\u0026#39;` mysql -uroot -p$temppasswd --connect-expired-password \u0026lt;\u0026lt; EOF SET GLOBAL validate_password.policy = low; SET GLOBAL validate_password.length = 6; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;123456\u0026#39;; USE mysql; UPDATE user SET host = \u0026#39;%\u0026#39; WHERE user = \u0026#39;root\u0026#39;; COMMIT; FLUSH PRIVILEGES; EXIT EOF systemctl restart mysqld echo -e \u0026#34;\\e[1;44m【添加时间同步服务至开机启动】\\e[0m\u0026#34; sleep 2 touch /usr/local/scripts/auto_ntpdate.sh echo \u0026#39;#!/bin/bash\u0026#39; \u0026gt;\u0026gt; /usr/local/scripts/auto_ntpdate.sh echo \u0026#39;yum info ntp \u0026amp;\u0026amp; yum -y install ntp \u0026amp;\u0026amp; ntpdate cn.ntp.org.cn\u0026#39; \u0026gt;\u0026gt; /usr/local/scripts/auto_ntpdate.sh chmod +x /usr/local/scripts/auto_ntpdate.sh echo \u0026#39;/usr/local/scripts/auto_ntpdate.sh\u0026#39; \u0026gt;\u0026gt; /etc/rc.d/rc.local chmod +x /etc/rc.d/rc.local echo -e \u0026#34;\\e[1;44m【删除 JDK Tomcat MySQL 安装包和虚拟机初始化脚本】\\e[0m\u0026#34; sleep 2 rm jdk* -rf rm apache-tomcat* -rf rm mysql* -rf rm init.sh -rf echo -e \u0026#34;\\e[1;41m【即将关闭计算机】\\e[0m\u0026#34; sleep 2 shutdown -h now 服务器相互免秘钥 # 生成密钥 # 分别在三台机器上运行以下命令生成密钥对：\nssh-keygen -t rsa -P \u0026#39;\u0026#39; -f ~/.ssh/id_rsa 运行以上命令后会在~/.ssh/目录下生成一对密钥对。\n[root@node01 ~]# ls ~/.ssh/ id_rsa id_rsa.pub known_hosts 取消主机名与 host 校验 # 分别在三台机器上修改/etc/ssh/ssh_config文件的配置，在Host *节点下配置以下信息：\n# 严格的密钥检查 no StrictHostKeyChecking no # 如果不希望生成已知主机列表文件，可以将已知主机列表文件信息写入黑洞（不会再生成 known_hosts 文件） #UserKnownHostsFile /dev/null 这样以后再也不会弹出将该主机添加到当前设备的已知主机列表中的提示信息了。\n如果将已知主机列表文件信息写入了黑洞，那么远程访问时会弹出以下警告：\nWarning: Permanently added \u0026#39;node02,192.168.88.102\u0026#39; (ECDSA) to the list of known hosts. 这个警告不影响任何操作，只是看着比较碍眼。解决办法：在文件夹~/.ssh/下创建config文件，命令如下：\nvim ~/.ssh/config 在新建的文件中写入如下内容：LogLevel=quiet。\n拷贝公钥 # 接下来把自己的公钥互相传递给其他主机，这个公钥文件必须放在对方主机的~/.ssh/authorized_keys文件中。可以使用命令将公钥文件自动传递过去，分别在三台机器运行以下命令：\nssh-copy-id -i ~/.ssh/id_rsa.pub root@node01 ssh-copy-id -i ~/.ssh/id_rsa.pub root@node02 ssh-copy-id -i ~/.ssh/id_rsa.pub root@node03 前面已经通过脚本修改了 hosts 文件，添加了集群环境机器 IP 与域名映射，所以这里可以直接使用主机名。\n传输文件测试是否已免密或者使用 ssh 协议登录对方主机进行测试：\n[root@localhost ~]# scp anaconda-ks.cfg root@node02:~ Warning: Permanently added \u0026#39;node02,192.168.88.102\u0026#39; (ECDSA) to the list of known hosts. anaconda-ks.cfg [root@localhost ~]# ssh root@node02 Warning: Permanently added \u0026#39;node02,192.168.88.102\u0026#39; (ECDSA) to the list of known hosts. Last login: Sat Jun 4 21:07:25 2022 from node01 测试没问题后，shutdown -h now关机，拍摄快照方便后期回退。\n集群启动脚本 # 在/usr/local/bin目录下创建对应服务的脚本：\n[root@node01 ~]# vim /usr/local/bin/tomcat tomcat脚本内容如下：\n#!/bin/bash user=$(whoami) case $1 in \u0026#34;start\u0026#34;) for i in node01 node02 node03 do echo -e \u0026#34;\\e[1;34m==================== $i Tomcat 启动 ====================\\e[0m\u0026#34; ssh $user@$i \u0026#34;/opt/yjx/apache-tomcat-9.0.72/bin/startup.sh\u0026#34; done ;; \u0026#34;shutdown\u0026#34;) for i in node01 node02 node03 do echo -e \u0026#34;\\e[1;34m==================== $i Tomcat 停止 ====================\\e[0m\u0026#34; ssh $user@$i \u0026#34;/opt/yjx/apache-tomcat-9.0.72/bin/shutdown.sh\u0026#34; done ;; esac 修改脚本权限为用户读写执行rwx，组读执行r-x，其他用户无权限r--：\n[root@node01 ~]# chmod 754 /usr/local/bin/tomcat JPS 脚本 # jps 是 JDK 提供的一个查看当前系统 Java 进程的小工具，全称是 Java Virtual Machine Process Status Tool。\n常用选项如下：\n-q：忽略输出的类名，Jar 名以及传递给 main 方法的参数，只输出 PID -m：输出传递给 main 方法的参数，如果是内嵌的 JVM 则输出为 null -l：输出应用程序主类的完整包名，或者是应用程序 JAR 文件的完整路径 -v：输出 JVM 的参数 -V：输出通过标记文件传递给 JVM 的参数(.hotspotrc 文件，或者通过参数-XX:Flags=\u0026lt;filename\u0026gt;指定的文件) -J：传递 JVM 参数到由 javac 调用的 java 加载器中，例如：-J-Xms512m，把启动内存设置为 512M。使用 -J 选项可以非常方便的向基于 Java 开发的底层虚拟机应用程序传递参数 顺便再创建一个查看所有服务器 JPS 进程的脚本。\n[root@node01 ~]# vim /usr/local/bin/jpsall jpsall脚本内容如下：\n#!/bin/bash # 获取当前用户名称 user=$(whoami) # $#：传递给脚本或函数的参数个数 params_count=$# # 如果没有参数，直接运行 \u0026#34;jps\u0026#34; if [ $params_count -lt 1 ] then for i in node01 node02 node03 do echo -e \u0026#34;\\e[1;34m==================== $i ====================\\e[0m\u0026#34; ssh $user@$i jps done exit fi # 如果有参数，运行 \u0026#34;jps -参数\u0026#34; for i in node01 node02 node03 do echo -e \u0026#34;\\e[1;34m==================== $i ====================\\e[0m\u0026#34; params=\u0026#34;\u0026#34; for p in $@ do params+=\u0026#34;$p \u0026#34; done ssh $user@$i \u0026#34;jps $params\u0026#34; done 修改脚本权限为用户读写执行rwx，组读执行r-x，其他用户读执行r-x：\n[root@node01 ~]# chmod 755 /usr/local/bin/jpsall 文件分发脚本 # 在/usr/local/bin目录下创建yjxrsync脚本，如下：\n[root@node01 ~]# vim /usr/local/bin/yjxrsync yjxrsync脚本内容如下：\n#!/bin/bash # 获取输入参数的个数 param_count=$# # 如果没有参数，直接退出 if [ $param_count -lt 1 ] then echo -e \u0026#34;\\e[1;31myjxrsync: You must pass in the file name parameter.\\e[0m\u0026#34; exit fi # 获取当前用户名称 user=$(whoami) # 如果有参数，遍历参数（文件或目录名称） for p in $@ do echo -e \u0026#34;\\e[1;34m==================== $p 开始同步 ====================\\e[0m\u0026#34; # basename：显示文件路径名的基本文件名，例如 /opt/bd 会显示 bd；/opt/bd/test.txt 会显示 test.txt file_name=$(basename $p) echo file_name=$file_name # 获取文件的上级目录的绝对路径 # -P：如果切换的目标目录是一个符号链接，则直接切换到符号链接指向的目标目录 parent_dir=`cd -P $(dirname $p); pwd` echo parent_dir=$parent_dir # 循环处理文件 for i in node01 node02 node03 do echo -e \u0026#34;\\e[1;34m==================== $i ====================\\e[0m\u0026#34; rsync -av --delete $parent_dir/$file_name $user@$i:$parent_dir done done 修改脚本权限为用户读写执行rwx，组读执行r-x，其他用户无权限---：\n[root@node01 ~]# chmod 750 /usr/local/bin/yjxrsync ","date":"2024-07-01","externalUrl":null,"permalink":"/docs/shell/","section":"Docs","summary":"Shell 编程概述 # Shell 本身并不是内核的一部分，它只是站在内核的基础上编写的一个应用程序，它和 QQ、迅雷、Firefox 等其它软件没有什么区别。然而 Shell 也有着它的特殊性，就是开机立马启动，并呈现在用户面前；用户通过 Shell 来使用 Linux，不启动 Shell 的话，用户就没办法使用 Linux。","title":"Shell","type":"docs"},{"content":"hhhh 使用PicGo图床了\n","date":"2024-07-01","externalUrl":null,"permalink":"/docs/test/","section":"Docs","summary":"hhhh 使用PicGo图床了","title":"test","type":"docs"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/docs/","section":"Docs","summary":"","title":"Docs","type":"docs"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/tags/hbase/","section":"Tags","summary":"","title":"HBase","type":"tags"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/tags/picgo/","section":"Tags","summary":"","title":"PicGo","type":"tags"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/tags/shell/","section":"Tags","summary":"","title":"Shell","type":"tags"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/tags/%E5%88%86%E4%BA%AB/","section":"Tags","summary":"","title":"分享","type":"tags"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/","section":"河爷","summary":"","title":"河爷","type":"page"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/tags/%E5%9B%BE%E5%BA%8A/","section":"Tags","summary":"","title":"图床","type":"tags"},{"content":"","date":"2024-07-01","externalUrl":null,"permalink":"/tags/%E8%BF%90%E7%BB%B4/","section":"Tags","summary":"","title":"运维","type":"tags"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]